{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training.train import load_tfrecord_dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"/home/phatdat/Desktop/Sleep-Apnea-Detection/model/checkpoints/bootstrap\"\n",
    "DATA_PATH = \"/mnt/dat/prepped/apnea_sp02_pr_bootstrap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints = glob.glob(os.path.join(CHECKPOINT_PATH, \"*.keras\"))\n",
    "bootstrap_part = glob.glob(os.path.join(DATA_PATH, \"train*.tfrecord\"))\n",
    "\n",
    "len(bootstrap_part), len(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred(model, dataset, batch_size, verbose=True):\n",
    "    y_pred_prob = model.predict(dataset, batch_size=batch_size, verbose=verbose)\n",
    "    y_true = []\n",
    "    for _, y in dataset:\n",
    "        y_true.append(y.numpy())\n",
    "    y_true = np.vstack(y_true)\n",
    "    return y_true, y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_spec(y_true, y_pred_probs, threshold=None):\n",
    "    \"\"\"\n",
    "    Calculate the geometric mean (G-mean) for a given threshold.\n",
    "    \"\"\"\n",
    "    # Convert predicted probabilities to binary predictions based on threshold\n",
    "    if threshold is None:\n",
    "        y_pred = y_pred_probs\n",
    "    else:\n",
    "        y_pred = (y_pred_probs >= threshold).astype(int)\n",
    "        \n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Compute sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    return sensitivity, specificity\n",
    "\n",
    "def optimize_threshold(y_true, y_pred_probs):\n",
    "    \"\"\"\n",
    "    Find the threshold that maximizes the G-mean for binary classification.\n",
    "    \"\"\"\n",
    "    best_threshold = -1\n",
    "    best_gmean = -1\n",
    "    thresholds = np.linspace(0, 0.1, 101)\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        sensitivity, specificity = sen_spec(y_true, y_pred_probs, threshold)\n",
    "        gmean = np.sqrt(sensitivity * specificity)\n",
    "\n",
    "        if gmean > best_gmean:\n",
    "            best_gmean = gmean\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_path = os.path.join(DATA_PATH, \"test_1.tfrecord\")\n",
    "test2_path = os.path.join(DATA_PATH, \"test_2.tfrecord\")\n",
    "\n",
    "\n",
    "test1_set, _ = load_tfrecord_dataset(test1_path, batch_size=1024, shuffle=False)\n",
    "test2_set, _ = load_tfrecord_dataset(test2_path, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]2024-12-06 09:44:31.871433: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:370] TFRecordDataset `buffer_size` is unspecified, default to 262144\n",
      "I0000 00:00:1733453071.936681    7968 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-06 09:45:03.723041: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-06 09:45:35.565177: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-06 09:45:46.060462: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "  2%|▏         | 1/41 [01:14<49:32, 74.30s/it]2024-12-06 09:46:58.488345: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "  7%|▋         | 3/41 [03:39<46:15, 73.03s/it]2024-12-06 09:49:22.847011: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      " 17%|█▋        | 7/41 [08:27<40:50, 72.07s/it]2024-12-06 09:54:11.205066: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      " 37%|███▋      | 15/41 [17:58<30:55, 71.36s/it]2024-12-06 10:03:41.374770: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      " 76%|███████▌  | 31/41 [37:02<11:49, 70.93s/it]2024-12-06 10:22:44.332604: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████| 41/41 [48:49<00:00, 71.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((41, 2, 5344888, 1), (41, 2, 875086, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shhs1_res = []\n",
    "shhs2_res = []\n",
    "\n",
    "for cp_path in tqdm(checkpoints, total=len(checkpoints)):\n",
    "    model = keras.models.load_model(cp_path)\n",
    "    \n",
    "    y_test1_true, y_test1_pred_prob = get_true_pred(model, test1_set, batch_size=1024, verbose=False)\n",
    "    y_test2_true, y_test2_pred_prob = get_true_pred(model, test2_set, batch_size=1024, verbose=False)\n",
    "    \n",
    "    shhs1_res.append((y_test1_true, y_test1_pred_prob))\n",
    "    shhs2_res.append((y_test2_true, y_test2_pred_prob))\n",
    "\n",
    "shhs1_res = np.array(shhs1_res)\n",
    "shhs2_res = np.array(shhs2_res)\n",
    "\n",
    "shhs1_res.shape, shhs2_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shhs1_res = np.mean(shhs1_res, axis=0)\n",
    "shhs2_res = np.mean(shhs2_res, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 5344888), (2, 875086))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shhs1_res = np.squeeze(shhs1_res)\n",
    "shhs2_res = np.squeeze(shhs2_res)\n",
    "shhs1_res.shape, shhs2_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5344888,), (5344888,), (875086,), (875086,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1_true = shhs1_res[0].astype(int)\n",
    "y_test1_pred_prob = shhs1_res[1]\n",
    "y_test1_pred = np.round(y_test1_pred_prob).astype(int)\n",
    "\n",
    "y_test2_true = shhs2_res[0].astype(int)\n",
    "y_test2_pred_prob = shhs2_res[1]\n",
    "y_test2_pred = np.round(y_test2_pred_prob).astype(int)\n",
    "\n",
    "y_test1_true.shape, y_test1_pred.shape, y_test2_true.shape, y_test2_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>SHHS2 Test</td>\n",
       "      <td>SHHS1 Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.882886</td>\n",
       "      <td>0.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.848186</td>\n",
       "      <td>0.685779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.883814</td>\n",
       "      <td>0.918008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.321267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision (PPV)</th>\n",
       "      <td>0.163329</td>\n",
       "      <td>0.209769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prauc</th>\n",
       "      <td>0.398854</td>\n",
       "      <td>0.365969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocauc</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.801893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0           1\n",
       "set              SHHS2 Test  SHHS1 Test\n",
       "acc                0.882886    0.910864\n",
       "sensitivity        0.848186    0.685779\n",
       "specificity        0.883814    0.918008\n",
       "f1-score           0.273913    0.321267\n",
       "precision (PPV)    0.163329    0.209769\n",
       "prauc              0.398854    0.365969\n",
       "rocauc                0.866    0.801893"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(list)\n",
    "\n",
    "sen1, spec1 = sen_spec(y_test1_true, y_test1_pred)\n",
    "sen2, spec2 = sen_spec(y_test2_true, y_test2_pred)\n",
    "\n",
    "metrics1 = classification_report(y_test1_true, y_test1_pred, output_dict=True)\n",
    "metrics2 = classification_report(y_test2_true, y_test2_pred, output_dict=True)\n",
    "\n",
    "rocauc1 = roc_auc_score(y_test1_true, y_test1_pred)\n",
    "rocauc2 = roc_auc_score(y_test2_true, y_test2_pred)\n",
    "\n",
    "precision1, recall1, _ = precision_recall_curve(y_test1_true, y_test1_pred_prob)\n",
    "pr_auc1 = auc(recall1, precision1)\n",
    "precision2, recall2, _ = precision_recall_curve(y_test2_true, y_test2_pred_prob)\n",
    "pr_auc2 = auc(recall2, precision2)\n",
    "\n",
    "\n",
    "results['set'].append(\"SHHS2 Test\")\n",
    "results['acc'].append(metrics2['accuracy'])\n",
    "results['sensitivity'].append(sen2)\n",
    "results['specificity'].append(spec2)\n",
    "results['f1-score'].append(metrics2['1']['f1-score'])\n",
    "results['precision (PPV)'].append(metrics2['1']['precision'])\n",
    "results['prauc'].append(pr_auc2)\n",
    "results['rocauc'].append(rocauc2)\n",
    "\n",
    "results['set'].append(\"SHHS1 Test\")\n",
    "results['acc'].append(metrics1['accuracy'])\n",
    "results['sensitivity'].append(sen1)\n",
    "results['specificity'].append(spec1)\n",
    "results['f1-score'].append(metrics1['1']['f1-score'])\n",
    "results['precision (PPV)'].append(metrics1['1']['precision'])\n",
    "results['prauc'].append(pr_auc1)\n",
    "results['rocauc'].append(rocauc1)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
